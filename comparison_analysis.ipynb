{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":407317,"sourceType":"datasetVersion","datasetId":181273}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"try:\n    import albumentations as A, einops  # noqa\n    print(\"Albumentations & Einops found ✅\")\nexcept Exception:\n    !pip install -q albumentations==1.4.11 einops\n    import albumentations as A  # noqa\n\nimport os, glob, random, math, time\nimport numpy as np\nimport torch, torch.nn as nn, torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Reproducibility\nSEED = 42\nrandom.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Using device:\", DEVICE)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-18T09:44:14.220229Z","iopub.execute_input":"2025-08-18T09:44:14.220420Z","iopub.status.idle":"2025-08-18T09:44:14.229388Z","shell.execute_reply.started":"2025-08-18T09:44:14.220405Z","shell.execute_reply":"2025-08-18T09:44:14.228848Z"}},"outputs":[{"name":"stdout","text":"Albumentations & Einops found ✅\nUsing device: cuda\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"class LGGSegmentationDataset(Dataset):\n    \"\"\"\n    Expects the Kaggle LGG dataset directory:\n    /kaggle/input/lgg-mri-segmentation/kaggle_3m/<PATIENT>/*.tif (and *_mask.tif)\n    Works for .tif or .png/.jpg with *_mask suffix for masks.\n    Returns tensors with shape [1, H, W] for both image and mask.\n    \"\"\"\n    def __init__(self, root_dir, img_size=256, aug=False):\n        self.img_size = int(img_size)\n        self.samples = []\n        self.aug = aug\n\n        # Supported image extensions (including common variants)\n        exts = (\"*.tif\", \"*.png\", \"*.jpg\", \"*.jpeg\")\n\n        # Collect paired (image, mask) paths\n        for patient in sorted(os.listdir(root_dir)):\n            pdir = os.path.join(root_dir, patient)\n            if not os.path.isdir(pdir):\n                continue\n\n            img_files = []\n            for e in exts:\n                img_files.extend(glob.glob(os.path.join(pdir, e)))\n\n            # Exclude files that are already masks\n            img_files = [p for p in img_files if \"_mask\" not in os.path.basename(p)]\n            for img_path in sorted(img_files):\n                mask_path = None\n                base = os.path.splitext(img_path)[0]\n                for me in [\n                    base + \"_mask.tif\",\n                    base + \"_mask.png\",\n                    base + \"_mask.jpg\",\n                    base + \"_mask.jpeg\",\n                ]:\n                    if os.path.exists(me):\n                        mask_path = me\n                        break\n                if mask_path is not None:\n                    self.samples.append((img_path, mask_path))\n\n        print(f\"Loaded {len(self.samples)} pairs from {root_dir}\")\n\n        # Albumentations pipeline (same transforms applied to image + mask)\n        self.train_tf = A.Compose([\n            A.Resize(self.img_size, self.img_size),\n            A.HorizontalFlip(p=0.5),\n            A.VerticalFlip(p=0.2),\n            A.RandomRotate90(p=0.2),\n            A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=15, p=0.3, border_mode=0),\n            A.RandomBrightnessContrast(p=0.3),\n        ], additional_targets={\"mask\": \"mask\"})\n\n        self.val_tf = A.Compose([\n            A.Resize(self.img_size, self.img_size),\n        ], additional_targets={\"mask\": \"mask\"})\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        img_path, mask_path = self.samples[idx]\n\n        # Load as grayscale image to match original intent\n        img = np.array(Image.open(img_path).convert(\"L\"))   # [H, W], 0..255\n        mask = np.array(Image.open(mask_path).convert(\"L\")) # [H, W], 0..255\n\n        # Normalize and binarize mask\n        mask = (mask > 0).astype(np.float32)\n\n        tf = self.train_tf if self.aug else self.val_tf\n        # Albumentations returns a dict with 'image' and 'mask'\n        augmented = tf(image=img, mask=mask)\n        img_aug = augmented[\"image\"]\n        mask_aug = augmented[\"mask\"]\n\n        # Move to channel-first PyTorch tensors\n        img_tensor = (img_aug.astype(np.float32) / 255.0)[None, ...]  # [1, H, W]\n        mask_tensor = mask_aug.astype(np.float32)[None, ...]           # [1, H, W]\n\n        return torch.from_numpy(img_tensor), torch.from_numpy(mask_tensor)\n\n\n# --------- Create splits and loaders ---------\n\nDATA_ROOT = os.path.join(\"/kaggle\", \"input\", \"lgg-mri-segmentation\", \"kaggle_3m\")\nfull_dataset = LGGSegmentationDataset(DATA_ROOT, img_size=256, aug=False)\n\nn_total = len(full_dataset)\nn_train = int(0.8 * n_total)\nn_val = n_total - n_train\n\ntrain_subset, val_subset = random_split(full_dataset, [n_train, n_val], generator=torch.Generator().manual_seed(SEED))\n\n# Enable augmentation for training subset\ntrain_subset.dataset.aug = True\nval_subset.dataset.aug = False\n\nBATCH_SIZE = 8\n\ntrain_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\nval_loader   = DataLoader(val_subset,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\nprint(f\"Train: {len(train_subset)} | Val: {len(val_subset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T09:47:35.880472Z","iopub.execute_input":"2025-08-18T09:47:35.881184Z","iopub.status.idle":"2025-08-18T09:47:38.486843Z","shell.execute_reply.started":"2025-08-18T09:47:35.881159Z","shell.execute_reply":"2025-08-18T09:47:38.486108Z"}},"outputs":[{"name":"stdout","text":"Loaded 3929 pairs from /kaggle/input/lgg-mri-segmentation/kaggle_3m\nTrain: 3143 | Val: 786\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from pathlib import Path\nimport warnings\n\n# Set a consistent working directory and create output folders\nWORK_DIR = Path(\"/kaggle/working\")\n\n# Define all output directories under WORK_DIR\nPROCESSED_DATA_DIR = WORK_DIR / \"processed\" / \"lgg\"\nLOGS_DIR = WORK_DIR / \"logs\"\nCHECKPOINTS_DIR = WORK_DIR / \"checkpoints\"\nVISUALS_DIR = WORK_DIR / \"visuals\"\nMETADATA_DIR = WORK_DIR / \"metadata\"\n\n# Create directories if they don't exist\nfor d in [PROCESSED_DATA_DIR, LOGS_DIR, CHECKPOINTS_DIR, VISUALS_DIR, METADATA_DIR]:\n    d.mkdir(parents=True, exist_ok=True)\n\n# Ignore the Albumentations warning (if you still want to suppress it)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T09:48:53.276621Z","iopub.execute_input":"2025-08-18T09:48:53.276986Z","iopub.status.idle":"2025-08-18T09:48:53.282480Z","shell.execute_reply.started":"2025-08-18T09:48:53.276960Z","shell.execute_reply":"2025-08-18T09:48:53.281851Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# ============================\n# 2) Models\n# ============================\nclass DoubleConv(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True)\n        )\n    def forward(self, x): return self.conv(x)\n\nclass UNet(nn.Module):\n    def __init__(self, in_ch=1, out_ch=1):\n        super().__init__()\n        self.enc1 = DoubleConv(in_ch, 64)\n        self.enc2 = DoubleConv(64, 128)\n        self.enc3 = DoubleConv(128, 256)\n        self.pool = nn.MaxPool2d(2)\n        self.up1  = nn.ConvTranspose2d(256, 128, 2, stride=2)\n        self.dec1 = DoubleConv(256, 128)\n        self.up2  = nn.ConvTranspose2d(128, 64, 2, stride=2)\n        self.dec2 = DoubleConv(128, 64)\n        self.outc = nn.Conv2d(64, out_ch, 1)\n    def forward(self, x):\n        x1 = self.enc1(x)\n        x2 = self.enc2(self.pool(x1))\n        x3 = self.enc3(self.pool(x2))\n        x  = self.up1(x3)\n        x  = torch.cat([x, x2], dim=1); x = self.dec1(x)\n        x  = self.up2(x)\n        x  = torch.cat([x, x1], dim=1); x = self.dec2(x)\n        return self.outc(x)  # logits\n\nclass AttentionBlock(nn.Module):\n    def __init__(self, g_ch, x_ch, int_ch):\n        super().__init__()\n        self.Wg = nn.Conv2d(g_ch, int_ch, 1)\n        self.Wx = nn.Conv2d(x_ch, int_ch, 1)\n        self.psi = nn.Conv2d(int_ch, 1, 1)\n        self.relu = nn.ReLU(inplace=True)\n        self.sigmoid = nn.Sigmoid()\n    def forward(self, g, x):\n        psi = self.relu(self.Wg(g) + self.Wx(x))\n        psi = self.sigmoid(self.psi(psi))\n        return x * psi\n\nclass AttentionUNet(UNet):\n    def __init__(self, in_ch=1, out_ch=1):\n        super().__init__(in_ch, out_ch)\n        self.att1 = AttentionBlock(128, 128, 64)\n        self.att2 = AttentionBlock(64, 64, 32)\n    def forward(self, x):\n        x1 = self.enc1(x)\n        x2 = self.enc2(self.pool(x1))\n        x3 = self.enc3(self.pool(x2))\n        g1 = self.up1(x3)\n        x2 = self.att1(g1, x2)\n        x  = torch.cat([g1, x2], dim=1); x = self.dec1(x)\n        g2 = self.up2(x)\n        x1 = self.att2(g2, x1)\n        x  = torch.cat([g2, x1], dim=1); x = self.dec2(x)\n        return self.outc(x)  # logits\n\nclass SwinUNet(nn.Module):\n    \"\"\"Tiny CNN-based Swin-UNet stand-in (no transformer deps)\"\"\"\n    def __init__(self, in_ch=1, out_ch=1, base=64):\n        super().__init__()\n        self.enc1 = DoubleConv(in_ch, base)\n        self.enc2 = DoubleConv(base, base*2)\n        self.pool = nn.MaxPool2d(2)\n        self.bottleneck = DoubleConv(base*2, base*4)\n        self.up1  = nn.ConvTranspose2d(base*4, base*2, 2, stride=2)\n        self.dec1 = DoubleConv(base*4, base*2)\n        self.up2  = nn.ConvTranspose2d(base*2, base, 2, stride=2)\n        self.dec2 = DoubleConv(base*2, base)\n        self.outc = nn.Conv2d(base, out_ch, 1)\n    def forward(self, x):\n        x1 = self.enc1(x)\n        x2 = self.enc2(self.pool(x1))\n        x3 = self.bottleneck(self.pool(x2))\n        x  = self.up1(x3)\n        x  = torch.cat([x, x2], dim=1); x = self.dec1(x)\n        x  = self.up2(x)\n        x  = torch.cat([x, x1], dim=1); x = self.dec2(x)\n        return self.outc(x)  # logits\n\nclass MambaBlock(nn.Module):\n    \"\"\"Pure-PyTorch 'sequence mixing' stub\"\"\"\n    def __init__(self, ch):\n        super().__init__()\n        self.fc1 = nn.Conv2d(ch, ch, 1)\n        self.fc2 = nn.Conv2d(ch, ch, 1)\n        self.act = nn.GELU()\n        self.bn  = nn.BatchNorm2d(ch)\n    def forward(self, x):\n        skip = x\n        x = self.bn(self.act(self.fc1(x)))\n        x = self.fc2(x)\n        return x + skip\n\nclass MambaUNet(UNet):\n    def __init__(self, in_ch=1, out_ch=1):\n        super().__init__(in_ch, out_ch)\n        self.m1 = MambaBlock(64); self.m2 = MambaBlock(128); self.m3 = MambaBlock(256)\n    def forward(self, x):\n        x1 = self.m1(self.enc1(x))\n        x2 = self.m2(self.enc2(self.pool(x1)))\n        x3 = self.m3(self.enc3(self.pool(x2)))\n        x  = self.up1(x3)\n        x  = torch.cat([x, x2], dim=1); x = self.dec1(x)\n        x  = self.up2(x)\n        x  = torch.cat([x, x1], dim=1); x = self.dec2(x)\n        return self.outc(x)  # logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T09:48:56.522200Z","iopub.execute_input":"2025-08-18T09:48:56.522453Z","iopub.status.idle":"2025-08-18T09:48:56.540531Z","shell.execute_reply.started":"2025-08-18T09:48:56.522433Z","shell.execute_reply":"2025-08-18T09:48:56.539844Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# ============================  \n# 3) Losses & Metrics  \n# ============================  \ndef dice_coef(pred, target, eps=1e-6):  \n    # pred, target in {0,1}; shapes [N,1,H,W]  \n    inter = (pred * target).sum(dim=(2,3))  \n    union = pred.sum(dim=(2,3)) + target.sum(dim=(2,3))  \n    dice = (2*inter + eps) / (union + eps)  \n    return dice.mean().item()  \n\ndef iou_score(pred, target, eps=1e-6):  \n    inter = (pred * target).sum(dim=(2,3))  \n    union = pred.sum(dim=(2,3)) + target.sum(dim=(2,3)) - inter  \n    iou = (inter + eps) / (union + eps)  \n    return iou.mean().item()  \n\nclass DiceLoss(nn.Module):  \n    def __init__(self, eps=1e-6): super().__init__(); self.eps=eps  \n    def forward(self, logits, targets):  \n        probs = torch.sigmoid(logits)  \n        num = 2*(probs*targets).sum(dim=(2,3)) + self.eps  \n        den = probs.sum(dim=(2,3)) + targets.sum(dim=(2,3)) + self.eps  \n        return 1 - (num/den).mean()  \n\ndef combo_loss(logits, targets, bce_w=0.5):  \n    bce = F.binary_cross_entropy_with_logits(logits, targets)  \n    dice = DiceLoss()(logits, targets)  \n    return bce_w*bce + (1-bce_w)*dice  \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T09:51:27.359857Z","iopub.execute_input":"2025-08-18T09:51:27.360656Z","iopub.status.idle":"2025-08-18T09:51:27.368115Z","shell.execute_reply.started":"2025-08-18T09:51:27.360624Z","shell.execute_reply":"2025-08-18T09:51:27.367246Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# ============================  \n# 4) Train / Eval Utilities  \n# ============================  \ndef train_one_epoch(model, loader, opt, scaler=None):\n    model.train()\n    running = 0.0\n    for x, y in loader:\n        x, y = x.to(DEVICE, non_blocking=True), y.to(DEVICE, non_blocking=True)\n        opt.zero_grad(set_to_none=True)\n\n        if scaler is None:\n            # CPU path (no AMP)\n            logits = model(x)\n            loss = combo_loss(logits, y)\n            loss.backward()\n            opt.step()\n        else:\n            # CUDA + AMP path using new API\n            with torch.amp.autocast(\"cuda\"):\n                logits = model(x)\n                loss = combo_loss(logits, y)\n            scaler.scale(loss).backward()\n            scaler.step(opt)\n            scaler.update()\n\n        running += loss.item() * x.size(0)\n    return running / len(loader.dataset)\n@torch.no_grad()  \ndef evaluate(model, loader, thresh=0.5):  \n    model.eval()  \n    dices, ious = [], []  \n    for x, y in loader:  \n        x, y = x.to(DEVICE), y.to(DEVICE)  \n        logits = model(x)  \n        probs = torch.sigmoid(logits)  \n        pred = (probs > thresh).float()  \n        dices.append(dice_coef(pred, y))  \n        ious.append(iou_score(pred, y))  \n    return float(np.mean(ious)), float(np.mean(dices))  \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T09:55:36.062317Z","iopub.execute_input":"2025-08-18T09:55:36.062961Z","iopub.status.idle":"2025-08-18T09:55:36.071214Z","shell.execute_reply.started":"2025-08-18T09:55:36.062929Z","shell.execute_reply":"2025-08-18T09:55:36.070396Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# ============================\n# 5) Run Experiments (AMP updated)\n# ============================\nEPOCHS = 2          # keep small for quick runs; increase for better scores\nLR = 1e-3\nMODELS = {\n    \"UNet\": UNet(),\n    \"AttentionUNet\": AttentionUNet(),\n    \"SwinUNet\": SwinUNet(),\n    \"MambaUNet\": MambaUNet(),\n}\n\nresults = []\nfor name, net in MODELS.items():\n    print(f\"\\n----- Training {name} -----\")\n    net = net.to(DEVICE)\n    opt = torch.optim.AdamW(net.parameters(), lr=LR, weight_decay=1e-4)\n\n    # New AMP API usage\n    scaler = torch.amp.GradScaler() if DEVICE == \"cuda\" else None\n\n    best_val = -1\n    best_ckpt = None\n    for e in range(1, EPOCHS + 1):\n        # Use new autocast inside train_one_epoch if AMP is active\n        tr_loss = train_one_epoch(net, train_loader, opt, scaler)\n        iou, dice = evaluate(net, val_loader)\n        print(f\"Epoch {e:02d} | loss {tr_loss:.4f} | IoU {iou:.4f} | Dice {dice:.4f}\")\n        if dice > best_val:\n            best_val = dice\n            best_ckpt = {k: v.detach().cpu().clone() for k, v in net.state_dict().items()}\n\n    # load best (by Dice) and re-eval\n    if best_ckpt is not None:\n        net.load_state_dict(best_ckpt)\n    iou, dice = evaluate(net, val_loader)\n    results.append({\"Model\": name, \"IoU\": iou, \"Dice\": dice})\n\n# Results table\ndf = pd.DataFrame(results).sort_values(\"Dice\", ascending=False).reset_index(drop=True)\nprint(\"\\n=== Validation Results (higher is better) ===\")\nprint(df)\n\n# Optional: bar plot\nax = df.set_index(\"Model\")[[\"IoU\",\"Dice\"]].plot(kind=\"bar\", figsize=(7,4))\nax.set_ylabel(\"Score\"); ax.set_title(\"LGG Segmentation — IoU & Dice\")\nplt.xticks(rotation=0); plt.tight_layout(); plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T09:55:41.533155Z","iopub.execute_input":"2025-08-18T09:55:41.533426Z","iopub.status.idle":"2025-08-18T10:07:16.513218Z","shell.execute_reply.started":"2025-08-18T09:55:41.533406Z","shell.execute_reply":"2025-08-18T10:07:16.512352Z"}},"outputs":[{"name":"stdout","text":"\n----- Training UNet -----\nEpoch 01 | loss 0.5382 | IoU 0.6591 | Dice 0.6591\nEpoch 02 | loss 0.4812 | IoU 0.5660 | Dice 0.5858\n\n----- Training AttentionUNet -----\nEpoch 01 | loss 0.5115 | IoU 0.5339 | Dice 0.5608\nEpoch 02 | loss 0.4775 | IoU 0.5330 | Dice 0.5539\n\n----- Training SwinUNet -----\nEpoch 01 | loss 0.5176 | IoU 0.6005 | Dice 0.6189\nEpoch 02 | loss 0.4840 | IoU 0.4024 | Dice 0.4297\n\n----- Training MambaUNet -----\nEpoch 01 | loss 0.5147 | IoU 0.2935 | Dice 0.3223\nEpoch 02 | loss 0.4748 | IoU 0.5176 | Dice 0.5467\n\n=== Validation Results (higher is better) ===\n           Model       IoU      Dice\n0           UNet  0.659091  0.659091\n1       SwinUNet  0.600515  0.618906\n2  AttentionUNet  0.533945  0.560799\n3      MambaUNet  0.517584  0.546729\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 700x400 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"import os, glob\nroot=\"/kaggle/input/lgg-mri-segmentation/kaggle_3m\"\npairs=[]\nexts=(\"*.tif\",\"*.png\")\nfor p in sorted(os.listdir(root)):\n    d=os.path.join(root,p)\n    if not os.path.isdir(d): continue\n    files=[]\n    for e in exts: files+=glob.glob(os.path.join(d,e))\n    files=[f for f in sorted(files) if \"_mask\" not in os.path.basename(f)]\n    for img in files:\n        base=os.path.splitext(img)[0]\n        for m in (base+\"_mask.tif\", base+\"_mask.png\", base+\"_mask.jpg\"):\n            if os.path.exists(m):\n                pairs.append((img,m)); break\nprint(\"Pairs found:\", len(pairs))\nprint(\"First 10 pairs:\")\nfor a,b in pairs[:10]:\n    print(os.path.basename(a),\" <-> \", os.path.basename(b))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T10:18:17.460603Z","iopub.execute_input":"2025-08-18T10:18:17.461022Z","iopub.status.idle":"2025-08-18T10:18:23.299303Z","shell.execute_reply.started":"2025-08-18T10:18:17.460993Z","shell.execute_reply":"2025-08-18T10:18:23.298514Z"}},"outputs":[{"name":"stdout","text":"Pairs found: 3929\nFirst 10 pairs:\nTCGA_CS_4941_19960909_1.tif  <->  TCGA_CS_4941_19960909_1_mask.tif\nTCGA_CS_4941_19960909_10.tif  <->  TCGA_CS_4941_19960909_10_mask.tif\nTCGA_CS_4941_19960909_11.tif  <->  TCGA_CS_4941_19960909_11_mask.tif\nTCGA_CS_4941_19960909_12.tif  <->  TCGA_CS_4941_19960909_12_mask.tif\nTCGA_CS_4941_19960909_13.tif  <->  TCGA_CS_4941_19960909_13_mask.tif\nTCGA_CS_4941_19960909_14.tif  <->  TCGA_CS_4941_19960909_14_mask.tif\nTCGA_CS_4941_19960909_15.tif  <->  TCGA_CS_4941_19960909_15_mask.tif\nTCGA_CS_4941_19960909_16.tif  <->  TCGA_CS_4941_19960909_16_mask.tif\nTCGA_CS_4941_19960909_17.tif  <->  TCGA_CS_4941_19960909_17_mask.tif\nTCGA_CS_4941_19960909_18.tif  <->  TCGA_CS_4941_19960909_18_mask.tif\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Small check: show shapes, value ranges, unique mask values (first 12 pairs)\n# and dataset-level counts of empty / tiny masks.\nimport os, glob\nfrom PIL import Image\nimport numpy as np\n\nroot = \"/kaggle/input/lgg-mri-segmentation/kaggle_3m\"\nexts = (\"*.tif\",\"*.png\",\"*.jpg\")\n\npairs = []\nfor p in sorted(os.listdir(root)):\n    pd = os.path.join(root, p)\n    if not os.path.isdir(pd): continue\n    files = []\n    for e in exts: files += glob.glob(os.path.join(pd, e))\n    files = sorted([f for f in files if \"_mask\" not in os.path.basename(f)])\n    for img in files:\n        base = os.path.splitext(img)[0]\n        for m in (base + \"_mask.tif\", base + \"_mask.png\", base + \"_mask.jpg\"):\n            if os.path.exists(m):\n                pairs.append((img, m)); break\n\nprint(\"Total pairs found:\", len(pairs))\nprint(\"\\nFirst 12 pairs (basename):\")\nfor a,b in pairs[:12]:\n    print(os.path.basename(a), \"<->\", os.path.basename(b))\n\n# Inspect first N pairs for raw stats\nN = 12\nprint(\"\\nPer-file stats (first {}):\".format(N))\nfor img_path, mask_path in pairs[:N]:\n    I = np.array(Image.open(img_path).convert(\"L\"))\n    M = np.array(Image.open(mask_path).convert(\"L\"))\n    uniq = np.unique(M)\n    nonzero = (M>0).sum()\n    pct = 100.0 * nonzero / M.size\n    print(f\"{os.path.basename(img_path):40s} shape={I.shape} min/max={I.min()}/{I.max():3d} mean={I.mean():.1f}\")\n    print(f\"  {os.path.basename(mask_path):40s} shape={M.shape} unique_vals_sample={uniq[:10].tolist()}  nonzero_px={nonzero} ({pct:.3f}%)\")\n\n# Dataset-level counts (quick)\nempty_count = 0\ntiny_count = 0\nsmall_count = 0\nfor i,(img_path, mask_path) in enumerate(pairs):\n    M = np.array(Image.open(mask_path).convert(\"L\"))\n    nonzero = (M>0).sum()\n    if nonzero == 0:\n        empty_count += 1\n    pct = 100.0 * nonzero / M.size\n    if pct < 0.01:     # <0.01% coverage\n        tiny_count += 1\n    if pct < 1.0:      # <1% coverage\n        small_count += 1\n    if i >= 2000:      # limit for speed\n        break\n\ntotal_checked = min(len(pairs), 2001)\nprint(f\"\\nChecked {total_checked} masks (first {total_checked}):\")\nprint(\" Empty masks (0 pixels):\", empty_count)\nprint(\" Masks with coverage <0.01%:\", tiny_count)\nprint(\" Masks with coverage <1%:\", small_count)\nprint(\" Percent empty:\", 100.0*empty_count/total_checked, \"%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T10:19:18.106127Z","iopub.execute_input":"2025-08-18T10:19:18.106753Z","iopub.status.idle":"2025-08-18T10:19:21.072606Z","shell.execute_reply.started":"2025-08-18T10:19:18.106727Z","shell.execute_reply":"2025-08-18T10:19:21.071790Z"}},"outputs":[{"name":"stdout","text":"Total pairs found: 3929\n\nFirst 12 pairs (basename):\nTCGA_CS_4941_19960909_1.tif <-> TCGA_CS_4941_19960909_1_mask.tif\nTCGA_CS_4941_19960909_10.tif <-> TCGA_CS_4941_19960909_10_mask.tif\nTCGA_CS_4941_19960909_11.tif <-> TCGA_CS_4941_19960909_11_mask.tif\nTCGA_CS_4941_19960909_12.tif <-> TCGA_CS_4941_19960909_12_mask.tif\nTCGA_CS_4941_19960909_13.tif <-> TCGA_CS_4941_19960909_13_mask.tif\nTCGA_CS_4941_19960909_14.tif <-> TCGA_CS_4941_19960909_14_mask.tif\nTCGA_CS_4941_19960909_15.tif <-> TCGA_CS_4941_19960909_15_mask.tif\nTCGA_CS_4941_19960909_16.tif <-> TCGA_CS_4941_19960909_16_mask.tif\nTCGA_CS_4941_19960909_17.tif <-> TCGA_CS_4941_19960909_17_mask.tif\nTCGA_CS_4941_19960909_18.tif <-> TCGA_CS_4941_19960909_18_mask.tif\nTCGA_CS_4941_19960909_19.tif <-> TCGA_CS_4941_19960909_19_mask.tif\nTCGA_CS_4941_19960909_2.tif <-> TCGA_CS_4941_19960909_2_mask.tif\n\nPer-file stats (first 12):\nTCGA_CS_4941_19960909_1.tif              shape=(256, 256) min/max=0/158 mean=26.6\n  TCGA_CS_4941_19960909_1_mask.tif         shape=(256, 256) unique_vals_sample=[0]  nonzero_px=0 (0.000%)\nTCGA_CS_4941_19960909_10.tif             shape=(256, 256) min/max=0/206 mean=42.1\n  TCGA_CS_4941_19960909_10_mask.tif        shape=(256, 256) unique_vals_sample=[0]  nonzero_px=0 (0.000%)\nTCGA_CS_4941_19960909_11.tif             shape=(256, 256) min/max=0/195 mean=42.3\n  TCGA_CS_4941_19960909_11_mask.tif        shape=(256, 256) unique_vals_sample=[0, 255]  nonzero_px=1426 (2.176%)\nTCGA_CS_4941_19960909_12.tif             shape=(256, 256) min/max=0/190 mean=42.3\n  TCGA_CS_4941_19960909_12_mask.tif        shape=(256, 256) unique_vals_sample=[0, 255]  nonzero_px=2646 (4.037%)\nTCGA_CS_4941_19960909_13.tif             shape=(256, 256) min/max=0/193 mean=41.5\n  TCGA_CS_4941_19960909_13_mask.tif        shape=(256, 256) unique_vals_sample=[0, 255]  nonzero_px=2765 (4.219%)\nTCGA_CS_4941_19960909_14.tif             shape=(256, 256) min/max=0/174 mean=39.6\n  TCGA_CS_4941_19960909_14_mask.tif        shape=(256, 256) unique_vals_sample=[0, 255]  nonzero_px=2877 (4.390%)\nTCGA_CS_4941_19960909_15.tif             shape=(256, 256) min/max=0/170 mean=38.0\n  TCGA_CS_4941_19960909_15_mask.tif        shape=(256, 256) unique_vals_sample=[0, 255]  nonzero_px=1952 (2.979%)\nTCGA_CS_4941_19960909_16.tif             shape=(256, 256) min/max=0/169 mean=36.3\n  TCGA_CS_4941_19960909_16_mask.tif        shape=(256, 256) unique_vals_sample=[0, 255]  nonzero_px=1828 (2.789%)\nTCGA_CS_4941_19960909_17.tif             shape=(256, 256) min/max=0/169 mean=34.2\n  TCGA_CS_4941_19960909_17_mask.tif        shape=(256, 256) unique_vals_sample=[0, 255]  nonzero_px=811 (1.237%)\nTCGA_CS_4941_19960909_18.tif             shape=(256, 256) min/max=0/178 mean=31.9\n  TCGA_CS_4941_19960909_18_mask.tif        shape=(256, 256) unique_vals_sample=[0, 255]  nonzero_px=74 (0.113%)\nTCGA_CS_4941_19960909_19.tif             shape=(256, 256) min/max=0/167 mean=29.6\n  TCGA_CS_4941_19960909_19_mask.tif        shape=(256, 256) unique_vals_sample=[0]  nonzero_px=0 (0.000%)\nTCGA_CS_4941_19960909_2.tif              shape=(256, 256) min/max=0/186 mean=49.1\n  TCGA_CS_4941_19960909_2_mask.tif         shape=(256, 256) unique_vals_sample=[0]  nonzero_px=0 (0.000%)\n\nChecked 2001 masks (first 2001):\n Empty masks (0 pixels): 1334\n Masks with coverage <0.01%: 1334\n Masks with coverage <1%: 1474\n Percent empty: 66.66666666666667 %\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# RUN: shows coverage distribution for train and val splits\nimport numpy as np, cv2\nfrom tqdm import tqdm\n\ndef coverage_list(pairs, nlimit=None):\n    cov=[]\n    for i,(img,mask) in enumerate(pairs):\n        M = cv2.imread(mask, cv2.IMREAD_GRAYSCALE)\n        if M is None:\n            from PIL import Image\n            M = np.array(Image.open(mask).convert('L'))\n        Msmall = cv2.resize(M, (256,256), interpolation=cv2.INTER_NEAREST)\n        cov.append(100.0*(Msmall>0).sum()/Msmall.size)\n        if nlimit and i+1>=nlimit: break\n    return np.array(cov)\n\n# Build pairs list same as before\nimport glob, os\nroot=\"/kaggle/input/lgg-mri-segmentation/kaggle_3m\"\npairs=[]\nexts=(\"*.tif\",\"*.png\",\"*.jpg\")\nfor p in sorted(os.listdir(root)):\n    d=os.path.join(root,p)\n    if not os.path.isdir(d): continue\n    files=[]\n    for e in exts: files+=glob.glob(os.path.join(d,e))\n    files=[f for f in sorted(files) if \"_mask\" not in os.path.basename(f)]\n    for img in files:\n        base=os.path.splitext(img)[0]\n        for m in (base+\"_mask.tif\", base+\"_mask.png\", base+\"_mask.jpg\"):\n            if os.path.exists(m):\n                pairs.append((img,m)); break\n\n# compute coverage for first 2000 (fast)\ncov = coverage_list(pairs, nlimit=2000)\nprint(\"Overall (first 2000) - mean/std/min/max:\", cov.mean(), cov.std(), cov.min(), cov.max())\nprint(\"Percentiles:\", np.percentile(cov, [0,1,5,25,50,75,95,99,100]).tolist())\n\n# If you used random_split earlier, get indices from the same split and compute\n# assume you used random_split(full_ds, [n_train, n_val], generator=torch.Generator().manual_seed(42))\n# If you didn't store indices, just show simple counts:\nprint(\"Count of empty masks in sample:\", (cov==0).sum(), \"/\", len(cov))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T10:20:11.946663Z","iopub.execute_input":"2025-08-18T10:20:11.947231Z","iopub.status.idle":"2025-08-18T10:20:16.016496Z","shell.execute_reply.started":"2025-08-18T10:20:11.947205Z","shell.execute_reply":"2025-08-18T10:20:16.015666Z"}},"outputs":[{"name":"stdout","text":"Overall (first 2000) - mean/std/min/max: 0.9890090942382812 1.8992447828839054 0.0 11.480712890625\nPercentiles: [0.0, 0.0, 0.0, 0.0, 0.0, 1.1623382568359375, 5.44158935546875, 7.8813629150390625, 11.480712890625]\nCount of empty masks in sample: 1334 / 2000\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# Check A: mask unique values after a resize transform\nimport os, glob\nfrom PIL import Image\nimport numpy as np\nimport albumentations as A, cv2\n\nROOT = \"/kaggle/input/lgg-mri-segmentation/kaggle_3m\"\n# Use INTER_NEAREST for masks — we are testing current behavior with INTER_NEAREST\ntf_nearest = A.Compose([A.Resize(256,256, interpolation=cv2.INTER_NEAREST)])\ntf_linear  = A.Compose([A.Resize(256,256, interpolation=cv2.INTER_LINEAR)])\n\npairs=[]\nexts=(\"*.tif\",\"*.png\",\"*.jpg\")\nfor p in sorted(os.listdir(ROOT)):\n    d=os.path.join(ROOT,p)\n    if not os.path.isdir(d): continue\n    files=[]\n    for e in exts: files+=glob.glob(os.path.join(d,e))\n    files=[f for f in sorted(files) if \"_mask\" not in os.path.basename(f)]\n    for img in files:\n        base=os.path.splitext(img)[0]\n        for m in (base+\"_mask.tif\", base+\"_mask.png\", base+\"_mask.jpg\"):\n            if os.path.exists(m):\n                pairs.append((img,m)); break\n\nprint(\"Pairs total:\", len(pairs))\nfor img,mask in pairs[:12]:\n    M = np.array(Image.open(mask).convert('L'))\n    m_n = tf_nearest(image=np.zeros((10,10),dtype=np.uint8), mask=M)['mask']  # only mask resize\n    m_l = tf_linear(image=np.zeros((10,10),dtype=np.uint8), mask=M)['mask']\n    print(\n        os.path.basename(mask),\n        \" raw_unique:\", np.unique(M)[:6].tolist(),\n        \" -> nearest_unique:\", np.unique(m_n)[:6].tolist(),\n        \" -> linear_unique_sample:\", np.unique(m_l)[:8].tolist()\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T10:20:59.069957Z","iopub.execute_input":"2025-08-18T10:20:59.070692Z","iopub.status.idle":"2025-08-18T10:20:59.392932Z","shell.execute_reply.started":"2025-08-18T10:20:59.070664Z","shell.execute_reply":"2025-08-18T10:20:59.391905Z"}},"outputs":[{"name":"stdout","text":"Pairs total: 3929\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2674183508.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mm_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_nearest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# only mask resize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mm_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     print(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/albumentations/core/composition.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, force_apply, *args, **data)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/albumentations/core/composition.py\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    639\u001b[0m                         \u001b[0mshapes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# H,W\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_shape_consistency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvolume_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;31m# Do strict validation only if enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/albumentations/core/composition.py\u001b[0m in \u001b[0;36m_check_shape_consistency\u001b[0;34m(self, shapes, volume_shapes)\u001b[0m\n\u001b[1;32m    935\u001b[0m         \u001b[0;34m\"\"\"Check consistency of shapes.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m         \u001b[0;31m# Check H,W consistency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_check_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;31m# Check D,H,W consistency for volumes and 3D masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/albumentations/core/composition.py\u001b[0m in \u001b[0;36m_check_shapes\u001b[0;34m(shapes, is_check_shapes)\u001b[0m\n\u001b[1;32m    846\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_check_shapes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_check_shapes\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"Height and Width of image, mask or masks should be equal. You can disable shapes check \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m                 \u001b[0;34m\"by setting a parameter is_check_shapes=False of Compose class (do it only if you are sure \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Height and Width of image, mask or masks should be equal. You can disable shapes check by setting a parameter is_check_shapes=False of Compose class (do it only if you are sure about your data consistency)."],"ename":"ValueError","evalue":"Height and Width of image, mask or masks should be equal. You can disable shapes check by setting a parameter is_check_shapes=False of Compose class (do it only if you are sure about your data consistency).","output_type":"error"}],"execution_count":19},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}