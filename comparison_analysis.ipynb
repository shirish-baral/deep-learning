{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7887a7bc",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-24T10:01:24.532407Z",
     "iopub.status.busy": "2025-08-24T10:01:24.532164Z",
     "iopub.status.idle": "2025-08-24T10:01:35.298110Z",
     "shell.execute_reply": "2025-08-24T10:01:35.297167Z"
    },
    "papermill": {
     "duration": 10.771965,
     "end_time": "2025-08-24T10:01:35.299291",
     "exception": false,
     "start_time": "2025-08-24T10:01:24.527326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Albumentations & Einops found ✅\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import albumentations as A, einops  # noqa\n",
    "    print(\"Albumentations & Einops found ✅\")\n",
    "except Exception:\n",
    "    !pip install -q albumentations==1.4.11 einops\n",
    "    import albumentations as A  # noqa\n",
    "\n",
    "import os, glob, random, math, time\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a690f841",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T10:01:35.307599Z",
     "iopub.status.busy": "2025-08-24T10:01:35.307228Z",
     "iopub.status.idle": "2025-08-24T10:01:46.544547Z",
     "shell.execute_reply": "2025-08-24T10:01:46.543603Z"
    },
    "papermill": {
     "duration": 11.243609,
     "end_time": "2025-08-24T10:01:46.546756",
     "exception": false,
     "start_time": "2025-08-24T10:01:35.303147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3929 pairs from /kaggle/input/lgg-mri-segmentation/kaggle_3m\n",
      "Train: 3143 | Val: 786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n"
     ]
    }
   ],
   "source": [
    "class LGGSegmentationDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Expects the Kaggle LGG dataset directory:\n",
    "    /kaggle/input/lgg-mri-segmentation/kaggle_3m/<PATIENT>/*.tif (and *_mask.tif)\n",
    "    Works for .tif or .png/.jpg with *_mask suffix for masks.\n",
    "    Returns tensors with shape [1, H, W] for both image and mask.\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, img_size=256, aug=False):\n",
    "        self.img_size = int(img_size)\n",
    "        self.samples = []\n",
    "        self.aug = aug\n",
    "\n",
    "        # Supported image extensions (including common variants)\n",
    "        exts = (\"*.tif\", \"*.png\", \"*.jpg\", \"*.jpeg\")\n",
    "\n",
    "        # Collect paired (image, mask) paths\n",
    "        for patient in sorted(os.listdir(root_dir)):\n",
    "            pdir = os.path.join(root_dir, patient)\n",
    "            if not os.path.isdir(pdir):\n",
    "                continue\n",
    "\n",
    "            img_files = []\n",
    "            for e in exts:\n",
    "                img_files.extend(glob.glob(os.path.join(pdir, e)))\n",
    "\n",
    "            # Exclude files that are already masks\n",
    "            img_files = [p for p in img_files if \"_mask\" not in os.path.basename(p)]\n",
    "            for img_path in sorted(img_files):\n",
    "                mask_path = None\n",
    "                base = os.path.splitext(img_path)[0]\n",
    "                for me in [\n",
    "                    base + \"_mask.tif\",\n",
    "                    base + \"_mask.png\",\n",
    "                    base + \"_mask.jpg\",\n",
    "                    base + \"_mask.jpeg\",\n",
    "                ]:\n",
    "                    if os.path.exists(me):\n",
    "                        mask_path = me\n",
    "                        break\n",
    "                if mask_path is not None:\n",
    "                    self.samples.append((img_path, mask_path))\n",
    "\n",
    "        print(f\"Loaded {len(self.samples)} pairs from {root_dir}\")\n",
    "\n",
    "        # Albumentations pipeline (same transforms applied to image + mask)\n",
    "        self.train_tf = A.Compose([\n",
    "            A.Resize(self.img_size, self.img_size),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.2),\n",
    "            A.RandomRotate90(p=0.2),\n",
    "            A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=15, p=0.3, border_mode=0),\n",
    "            A.RandomBrightnessContrast(p=0.3),\n",
    "        ], additional_targets={\"mask\": \"mask\"})\n",
    "\n",
    "        self.val_tf = A.Compose([\n",
    "            A.Resize(self.img_size, self.img_size),\n",
    "        ], additional_targets={\"mask\": \"mask\"})\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, mask_path = self.samples[idx]\n",
    "\n",
    "        # Load as grayscale image to match original intent\n",
    "        img = np.array(Image.open(img_path).convert(\"L\"))   # [H, W], 0..255\n",
    "        mask = np.array(Image.open(mask_path).convert(\"L\")) # [H, W], 0..255\n",
    "\n",
    "        # Normalize and binarize mask\n",
    "        mask = (mask > 0).astype(np.float32)\n",
    "\n",
    "        tf = self.train_tf if self.aug else self.val_tf\n",
    "        # Albumentations returns a dict with 'image' and 'mask'\n",
    "        augmented = tf(image=img, mask=mask)\n",
    "        img_aug = augmented[\"image\"]\n",
    "        mask_aug = augmented[\"mask\"]\n",
    "\n",
    "        # Move to channel-first PyTorch tensors\n",
    "        img_tensor = (img_aug.astype(np.float32) / 255.0)[None, ...]  # [1, H, W]\n",
    "        mask_tensor = mask_aug.astype(np.float32)[None, ...]           # [1, H, W]\n",
    "\n",
    "        return torch.from_numpy(img_tensor), torch.from_numpy(mask_tensor)\n",
    "\n",
    "\n",
    "# --------- Create splits and loaders ---------\n",
    "\n",
    "DATA_ROOT = os.path.join(\"/kaggle\", \"input\", \"lgg-mri-segmentation\", \"kaggle_3m\")\n",
    "full_dataset = LGGSegmentationDataset(DATA_ROOT, img_size=256, aug=False)\n",
    "\n",
    "n_total = len(full_dataset)\n",
    "n_train = int(0.8 * n_total)\n",
    "n_val = n_total - n_train\n",
    "\n",
    "train_subset, val_subset = random_split(full_dataset, [n_train, n_val], generator=torch.Generator().manual_seed(SEED))\n",
    "\n",
    "# Enable augmentation for training subset\n",
    "train_subset.dataset.aug = True\n",
    "val_subset.dataset.aug = False\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader   = DataLoader(val_subset,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "print(f\"Train: {len(train_subset)} | Val: {len(val_subset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f37a64b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T10:01:46.555871Z",
     "iopub.status.busy": "2025-08-24T10:01:46.555675Z",
     "iopub.status.idle": "2025-08-24T10:01:46.560792Z",
     "shell.execute_reply": "2025-08-24T10:01:46.560142Z"
    },
    "papermill": {
     "duration": 0.010642,
     "end_time": "2025-08-24T10:01:46.561910",
     "exception": false,
     "start_time": "2025-08-24T10:01:46.551268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Set a consistent working directory and create output folders\n",
    "WORK_DIR = Path(\"/kaggle/working\")\n",
    "\n",
    "# Define all output directories under WORK_DIR\n",
    "PROCESSED_DATA_DIR = WORK_DIR / \"processed\" / \"lgg\"\n",
    "LOGS_DIR = WORK_DIR / \"logs\"\n",
    "CHECKPOINTS_DIR = WORK_DIR / \"checkpoints\"\n",
    "VISUALS_DIR = WORK_DIR / \"visuals\"\n",
    "METADATA_DIR = WORK_DIR / \"metadata\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for d in [PROCESSED_DATA_DIR, LOGS_DIR, CHECKPOINTS_DIR, VISUALS_DIR, METADATA_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Ignore the Albumentations warning (if you still want to suppress it)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c77751f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T10:01:46.569409Z",
     "iopub.status.busy": "2025-08-24T10:01:46.569153Z",
     "iopub.status.idle": "2025-08-24T10:01:46.574659Z",
     "shell.execute_reply": "2025-08-24T10:01:46.574054Z"
    },
    "papermill": {
     "duration": 0.010407,
     "end_time": "2025-08-24T10:01:46.575711",
     "exception": false,
     "start_time": "2025-08-24T10:01:46.565304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# =================================\n",
    "# DoubleConv with optional MaxPooling\n",
    "# =================================\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, apply_pool=True):\n",
    "        super().__init__()\n",
    "        layers = [\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        ]\n",
    "        self.encode = nn.Sequential(*layers)\n",
    "        self.pool = nn.MaxPool2d(2) if apply_pool else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.encode(x)       # features before pooling (for skip)\n",
    "        if self.pool is not None:\n",
    "            down = self.pool(feat)  # pooled for next stage\n",
    "            return feat, down\n",
    "        return feat                 # bottleneck → no pooling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2028f5dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T10:01:46.583401Z",
     "iopub.status.busy": "2025-08-24T10:01:46.583090Z",
     "iopub.status.idle": "2025-08-24T10:01:46.589687Z",
     "shell.execute_reply": "2025-08-24T10:01:46.588999Z"
    },
    "papermill": {
     "duration": 0.011581,
     "end_time": "2025-08-24T10:01:46.590741",
     "exception": false,
     "start_time": "2025-08-24T10:01:46.579160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =================================\n",
    "# Original UNet (128-256-512-1024 encoder)\n",
    "# =================================\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_ch=1, out_ch=1):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.enc1 = DoubleConv(in_ch, 128)\n",
    "        self.enc2 = DoubleConv(128, 256)\n",
    "        self.enc3 = DoubleConv(256, 512)\n",
    "        self.enc4 = DoubleConv(512, 1024, apply_pool=False)\n",
    "\n",
    "        # Decoder\n",
    "        self.up0  = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n",
    "        self.dec0 = DoubleConv(1024, 512, apply_pool=False)\n",
    "\n",
    "        self.up1  = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
    "        self.dec1 = DoubleConv(512, 256, apply_pool=False)\n",
    "\n",
    "        self.up2  = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        self.dec2 = DoubleConv(256, 128, apply_pool=False)\n",
    "\n",
    "        # Output\n",
    "        self.outc = nn.Conv2d(128, out_ch, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1, p1 = self.enc1(x)\n",
    "        x2, p2 = self.enc2(p1)\n",
    "        x3, p3 = self.enc3(p2)\n",
    "        x4     = self.enc4(p3)\n",
    "\n",
    "        # Decoder\n",
    "        x = self.up0(x4)\n",
    "        x = torch.cat([x, x3], dim=1)\n",
    "        x = self.dec0(x)\n",
    "\n",
    "        x = self.up1(x)\n",
    "        x = torch.cat([x, x2], dim=1)\n",
    "        x = self.dec1(x)\n",
    "\n",
    "        x = self.up2(x)\n",
    "        x = torch.cat([x, x1], dim=1)\n",
    "        x = self.dec2(x)\n",
    "\n",
    "        return self.outc(x)  # logits\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d5b6cdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T10:01:46.598131Z",
     "iopub.status.busy": "2025-08-24T10:01:46.597925Z",
     "iopub.status.idle": "2025-08-24T10:01:46.605483Z",
     "shell.execute_reply": "2025-08-24T10:01:46.604759Z"
    },
    "papermill": {
     "duration": 0.012504,
     "end_time": "2025-08-24T10:01:46.606645",
     "exception": false,
     "start_time": "2025-08-24T10:01:46.594141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =================================\n",
    "# Attention U-Net (same-style attention)\n",
    "# =================================\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, g_ch, x_ch, int_ch):\n",
    "        super().__init__()\n",
    "        self.Wg = nn.Conv2d(g_ch, int_ch, 1, bias=False)\n",
    "        self.Wx = nn.Conv2d(x_ch, int_ch, 1, bias=False)\n",
    "        self.psi = nn.Conv2d(int_ch, 1, 1, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, g, x):\n",
    "        psi = self.relu(self.Wg(g) + self.Wx(x))\n",
    "        psi = self.sigmoid(self.psi(psi))\n",
    "        return x * psi\n",
    "\n",
    "class AttentionUNet(UNet):\n",
    "    def __init__(self, in_ch=1, out_ch=1):\n",
    "        super().__init__(in_ch, out_ch)\n",
    "        # add attentions at skip connections (channels must match the skip features)\n",
    "        self.att0 = AttentionBlock(512, 512, 128)  # for skip x3\n",
    "        self.att1 = AttentionBlock(256, 256, 64)   # for skip x2\n",
    "        self.att2 = AttentionBlock(128, 128, 32)   # for skip x1\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1, p1 = self.enc1(x)\n",
    "        x2, p2 = self.enc2(p1)\n",
    "        x3, p3 = self.enc3(p2)\n",
    "        x4     = self.enc4(p3)\n",
    "\n",
    "        # Decoder with attention gates\n",
    "        x = self.up0(x4)\n",
    "        x3 = self.att0(x, x3)   # attention on skip\n",
    "        x = torch.cat([x, x3], dim=1)\n",
    "        x = self.dec0(x)\n",
    "\n",
    "        x = self.up1(x)\n",
    "        x2 = self.att1(x, x2)\n",
    "        x = torch.cat([x, x2], dim=1)\n",
    "        x = self.dec1(x)\n",
    "\n",
    "        x = self.up2(x)\n",
    "        x1 = self.att2(x, x1)\n",
    "        x = torch.cat([x, x1], dim=1)\n",
    "        x = self.dec2(x)\n",
    "\n",
    "        return self.outc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5e2fd3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T10:01:46.614694Z",
     "iopub.status.busy": "2025-08-24T10:01:46.614264Z",
     "iopub.status.idle": "2025-08-24T10:01:46.621012Z",
     "shell.execute_reply": "2025-08-24T10:01:46.620329Z"
    },
    "papermill": {
     "duration": 0.011909,
     "end_time": "2025-08-24T10:01:46.622124",
     "exception": false,
     "start_time": "2025-08-24T10:01:46.610215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =================================\n",
    "# SimpleUNet — smaller, configurable base channels\n",
    "# =================================\n",
    "class SimpleUNet(nn.Module):\n",
    "    def __init__(self, in_ch=1, out_ch=1, base=64):\n",
    "        \"\"\"\n",
    "        Simpler U-Net with base channels configurable (default 64).\n",
    "        Good for quick experiments or limited memory.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.enc1 = DoubleConv(in_ch, base)\n",
    "        self.enc2 = DoubleConv(base, base*2)\n",
    "        self.enc3 = DoubleConv(base*2, base*4)\n",
    "        self.enc4 = DoubleConv(base*4, base*8, apply_pool=False)\n",
    "\n",
    "        self.up1  = nn.ConvTranspose2d(base*8, base*4, 2, stride=2)\n",
    "        self.dec1 = DoubleConv(base*8, base*4, apply_pool=False)\n",
    "\n",
    "        self.up2  = nn.ConvTranspose2d(base*4, base*2, 2, stride=2)\n",
    "        self.dec2 = DoubleConv(base*4, base*2, apply_pool=False)\n",
    "\n",
    "        self.up3  = nn.ConvTranspose2d(base*2, base, 2, stride=2)\n",
    "        self.dec3 = DoubleConv(base*2, base, apply_pool=False)\n",
    "\n",
    "        self.outc = nn.Conv2d(base, out_ch, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1, p1 = self.enc1(x)\n",
    "        x2, p2 = self.enc2(p1)\n",
    "        x3, p3 = self.enc3(p2)\n",
    "        x4     = self.enc4(p3)\n",
    "\n",
    "        x = self.up1(x4)\n",
    "        x = torch.cat([x, x3], dim=1); x = self.dec1(x)\n",
    "\n",
    "        x = self.up2(x)\n",
    "        x = torch.cat([x, x2], dim=1); x = self.dec2(x)\n",
    "\n",
    "        x = self.up3(x)\n",
    "        x = torch.cat([x, x1], dim=1); x = self.dec3(x)\n",
    "\n",
    "        return self.outc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52957dc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T10:01:46.630108Z",
     "iopub.status.busy": "2025-08-24T10:01:46.629894Z",
     "iopub.status.idle": "2025-08-24T10:01:46.642300Z",
     "shell.execute_reply": "2025-08-24T10:01:46.641612Z"
    },
    "papermill": {
     "duration": 0.017663,
     "end_time": "2025-08-24T10:01:46.643409",
     "exception": false,
     "start_time": "2025-08-24T10:01:46.625746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =================================\n",
    "# ResUNet (residual blocks) — adapted from your sample\n",
    "# =================================\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual block with two conv layers and optional 1x1 shortcut.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        # Main path\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # Shortcut connection if channels differ\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.shortcut(x)\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x = x + shortcut\n",
    "        return self.relu(x)\n",
    "\n",
    "\n",
    "class ResUNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Residual U-Net — uses ResidualBlock for encoder & decoder.\n",
    "    base controls the channel depth (64 recommended).\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch=1, out_ch=1, base=64):\n",
    "        super().__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder1 = ResidualBlock(in_ch, base)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.encoder2 = ResidualBlock(base, base*2)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.encoder3 = ResidualBlock(base*2, base*4)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.encoder4 = ResidualBlock(base*4, base*8)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = ResidualBlock(base*8, base*16)\n",
    "\n",
    "        # Decoder\n",
    "        self.upconv1 = nn.ConvTranspose2d(base*16, base*8, kernel_size=2, stride=2)\n",
    "        self.decoder1 = ResidualBlock(base*16, base*8)\n",
    "\n",
    "        self.upconv2 = nn.ConvTranspose2d(base*8, base*4, kernel_size=2, stride=2)\n",
    "        self.decoder2 = ResidualBlock(base*8, base*4)\n",
    "\n",
    "        self.upconv3 = nn.ConvTranspose2d(base*4, base*2, kernel_size=2, stride=2)\n",
    "        self.decoder3 = ResidualBlock(base*4, base*2)\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose2d(base*2, base, kernel_size=2, stride=2)\n",
    "        self.decoder4 = ResidualBlock(base*2, base)\n",
    "\n",
    "        # Output\n",
    "        self.output_conv = nn.Conv2d(base, out_ch, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        s1 = self.encoder1(x)\n",
    "        p1 = self.pool1(s1)\n",
    "        s2 = self.encoder2(p1)\n",
    "        p2 = self.pool2(s2)\n",
    "        s3 = self.encoder3(p2)\n",
    "        p3 = self.pool3(s3)\n",
    "        s4 = self.encoder4(p3)\n",
    "        p4 = self.pool4(s4)\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(p4)\n",
    "\n",
    "        # Decoder\n",
    "        d1 = self.upconv1(b)\n",
    "        d1 = torch.cat([d1, s4], dim=1)\n",
    "        d1 = self.decoder1(d1)\n",
    "\n",
    "        d2 = self.upconv2(d1)\n",
    "        d2 = torch.cat([d2, s3], dim=1)\n",
    "        d2 = self.decoder2(d2)\n",
    "\n",
    "        d3 = self.upconv3(d2)\n",
    "        d3 = torch.cat([d3, s2], dim=1)\n",
    "        d3 = self.decoder3(d3)\n",
    "\n",
    "        d4 = self.upconv4(d3)\n",
    "        d4 = torch.cat([d4, s1], dim=1)\n",
    "        d4 = self.decoder4(d4)\n",
    "\n",
    "        output = self.output_conv(d4)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "577618fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T10:01:46.651021Z",
     "iopub.status.busy": "2025-08-24T10:01:46.650798Z",
     "iopub.status.idle": "2025-08-24T10:01:46.659323Z",
     "shell.execute_reply": "2025-08-24T10:01:46.658629Z"
    },
    "papermill": {
     "duration": 0.013684,
     "end_time": "2025-08-24T10:01:46.660434",
     "exception": false,
     "start_time": "2025-08-24T10:01:46.646750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =================================\n",
    "# UNet++ (compact 3-depth nested UNet++)\n",
    "# =================================\n",
    "class UNetPlusPlus(nn.Module):\n",
    "    def __init__(self, in_ch=1, out_ch=1, base=32):\n",
    "        super().__init__()\n",
    "        # Level-0..3 encoders\n",
    "        self.enc0_0 = DoubleConv(in_ch, base)\n",
    "        self.enc1_0 = DoubleConv(base, base*2)\n",
    "        self.enc2_0 = DoubleConv(base*2, base*4)\n",
    "        self.enc3_0 = DoubleConv(base*4, base*8, apply_pool=False)\n",
    "\n",
    "        # Nested/up blocks\n",
    "        self.up3_0 = nn.ConvTranspose2d(base*8, base*4, 2, stride=2)\n",
    "        # x2_1 = up3_0(x3_0) [base*4] concat x2_0 [base*4] -> input channels = base*8\n",
    "        self.conv2_1 = DoubleConv(base*8, base*4, apply_pool=False)\n",
    "\n",
    "        self.up2_1 = nn.ConvTranspose2d(base*4, base*2, 2, stride=2)\n",
    "        # x1_2 = up2_1(x2_1) [base*2] concat x1_0 [base*2] -> input channels = base*4\n",
    "        self.conv1_2 = DoubleConv(base*4, base*2, apply_pool=False)\n",
    "\n",
    "        self.up1_2 = nn.ConvTranspose2d(base*2, base, 2, stride=2)\n",
    "        # x0_3 = up1_2(x1_2) [base] concat x0_0 [base] -> input channels = base*2\n",
    "        self.conv0_3 = DoubleConv(base*2, base, apply_pool=False)\n",
    "\n",
    "        # simpler skip decoders for final output\n",
    "        self.up2_0 = nn.ConvTranspose2d(base*4, base*2, 2, stride=2)\n",
    "        self.dec1 = DoubleConv(base*4, base*2, apply_pool=False)\n",
    "\n",
    "        self.up1_0 = nn.ConvTranspose2d(base*2, base, 2, stride=2)\n",
    "        self.dec0 = DoubleConv(base*2, base, apply_pool=False)\n",
    "\n",
    "        # reduce fused channels (created here — NOT in forward)\n",
    "        # fused = concat(d1 [base], x0_3 [base]) -> base*2\n",
    "        self.reduce = nn.Conv2d(base*2, base, 1)\n",
    "\n",
    "        self.outc = nn.Conv2d(base, out_ch, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0_0, p0 = self.enc0_0(x)\n",
    "        x1_0, p1 = self.enc1_0(p0)\n",
    "        x2_0, p2 = self.enc2_0(p1)\n",
    "        x3_0      = self.enc3_0(p2)\n",
    "\n",
    "        x2_1 = self.up3_0(x3_0)\n",
    "        x2_1 = torch.cat([x2_1, x2_0], dim=1)\n",
    "        x2_1 = self.conv2_1(x2_1)\n",
    "\n",
    "        x1_2 = self.up2_1(x2_1)\n",
    "        x1_2 = torch.cat([x1_2, x1_0], dim=1)\n",
    "        x1_2 = self.conv1_2(x1_2)\n",
    "\n",
    "        x0_3 = self.up1_2(x1_2)\n",
    "        x0_3 = torch.cat([x0_3, x0_0], dim=1)\n",
    "        x0_3 = self.conv0_3(x0_3)\n",
    "\n",
    "        d2 = self.up2_0(x2_1)\n",
    "        d2 = torch.cat([d2, x1_0], dim=1)\n",
    "        d2 = self.dec1(d2)\n",
    "\n",
    "        d1 = self.up1_0(d2)\n",
    "        d1 = torch.cat([d1, x0_0], dim=1)\n",
    "        d1 = self.dec0(d1)\n",
    "\n",
    "        fused = torch.cat([d1, x0_3], dim=1)  # fused channels = base * 2\n",
    "        fused = self.reduce(fused)\n",
    "        out = self.outc(fused)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8cb9d4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T10:01:46.667754Z",
     "iopub.status.busy": "2025-08-24T10:01:46.667550Z",
     "iopub.status.idle": "2025-08-24T10:01:52.714514Z",
     "shell.execute_reply": "2025-08-24T10:01:52.713585Z"
    },
    "papermill": {
     "duration": 6.052012,
     "end_time": "2025-08-24T10:01:52.715781",
     "exception": false,
     "start_time": "2025-08-24T10:01:46.663769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet: output (1, 1, 256, 256), params 30,782,593\n",
      "AttentionUNet: output (1, 1, 256, 256), params 30,954,849\n",
      "SimpleUNet: output (1, 1, 256, 256), params 7,699,009\n",
      "ResUNet: output (1, 1, 256, 256), params 8,113,601\n",
      "UNetPlusPlus: output (1, 1, 256, 256), params 2,108,193\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# =================================\n",
    "# End of model definitions\n",
    "# =================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # quick sanity check\n",
    "    device = torch.device(\"cpu\")\n",
    "    x = torch.randn(1, 1, 256, 256, device=device)\n",
    "\n",
    "    models = {\n",
    "        \"UNet\": UNet(in_ch=1, out_ch=1),\n",
    "        \"AttentionUNet\": AttentionUNet(in_ch=1, out_ch=1),\n",
    "        \"SimpleUNet\": SimpleUNet(in_ch=1, out_ch=1, base=64),\n",
    "        \"ResUNet\": ResUNet(in_ch=1, out_ch=1, base=32),\n",
    "        \"UNetPlusPlus\": UNetPlusPlus(in_ch=1, out_ch=1, base=32),\n",
    "    }\n",
    "\n",
    "    for name, m in models.items():\n",
    "        try:\n",
    "            m = m.to(device)\n",
    "            with torch.no_grad():\n",
    "                y = m(x)\n",
    "            params = sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
    "            print(f\"{name}: output {tuple(y.shape)}, params {params:,}\")\n",
    "        except Exception as e:\n",
    "            print(f\"{name} failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fb0e612",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T10:01:52.725505Z",
     "iopub.status.busy": "2025-08-24T10:01:52.725290Z",
     "iopub.status.idle": "2025-08-24T10:01:52.733528Z",
     "shell.execute_reply": "2025-08-24T10:01:52.732969Z"
    },
    "papermill": {
     "duration": 0.013794,
     "end_time": "2025-08-24T10:01:52.734536",
     "exception": false,
     "start_time": "2025-08-24T10:01:52.720742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================  \n",
    "# 3) Losses & Metrics  \n",
    "# ============================  \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ----------------------------\n",
    "# Metrics\n",
    "# ----------------------------\n",
    "def dice_coef(pred: torch.Tensor, target: torch.Tensor, eps: float = 1e-6) -> float:\n",
    "    \"\"\"\n",
    "    Computes the Dice coefficient between binary predictions and targets.\n",
    "    Args:\n",
    "        pred   : tensor [N,1,H,W] {0,1}\n",
    "        target : tensor [N,1,H,W] {0,1}\n",
    "    Returns:\n",
    "        mean dice score (float)\n",
    "    \"\"\"\n",
    "    inter = (pred * target).sum(dim=(2, 3))\n",
    "    union = pred.sum(dim=(2, 3)) + target.sum(dim=(2, 3))\n",
    "    dice = (2 * inter + eps) / (union + eps)\n",
    "    return dice.mean().item()\n",
    "\n",
    "\n",
    "def iou_score(pred: torch.Tensor, target: torch.Tensor, eps: float = 1e-6) -> float:\n",
    "\n",
    "    inter = (pred * target).sum(dim=(2, 3))\n",
    "    union = pred.sum(dim=(2, 3)) + target.sum(dim=(2, 3)) - inter\n",
    "    iou = (inter + eps) / (union + eps)\n",
    "    return iou.mean().item()\n",
    "\n",
    "\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    " \n",
    "    def __init__(self, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "        probs = torch.sigmoid(logits)\n",
    "        num = 2 * (probs * targets).sum(dim=(2, 3)) + self.eps\n",
    "        den = probs.sum(dim=(2, 3)) + targets.sum(dim=(2, 3)) + self.eps\n",
    "        return 1 - (num / den).mean()\n",
    "\n",
    "\n",
    "def combo_loss(logits: torch.Tensor, targets: torch.Tensor, bce_w: float = 0.5) -> torch.Tensor:\n",
    "\n",
    "    bce  = F.binary_cross_entropy_with_logits(logits, targets)\n",
    "    dice = DiceLoss()(logits, targets)\n",
    "    return bce_w * bce + (1 - bce_w) * dice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "949036a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T10:01:52.742518Z",
     "iopub.status.busy": "2025-08-24T10:01:52.742324Z",
     "iopub.status.idle": "2025-08-24T10:01:52.750853Z",
     "shell.execute_reply": "2025-08-24T10:01:52.750295Z"
    },
    "papermill": {
     "duration": 0.013713,
     "end_time": "2025-08-24T10:01:52.751807",
     "exception": false,
     "start_time": "2025-08-24T10:01:52.738094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 4) Train / Eval Utilities (AMP-updated)\n",
    "# ============================\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def _is_cuda_device(dev):\n",
    "    \"\"\"Robust check whether `dev` refers to CUDA.\"\"\"\n",
    "    if isinstance(dev, torch.device):\n",
    "        return dev.type == \"cuda\"\n",
    "    # strings like \"cuda\", \"cuda:0\" or pathlib-like objects\n",
    "    s = str(dev).lower()\n",
    "    return \"cuda\" in s\n",
    "\n",
    "def train_one_epoch(model, loader, opt, scaler=None, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch.\n",
    "    Supports Automatic Mixed Precision (AMP) if `scaler` is provided\n",
    "    (use torch.amp.GradScaler(enabled=...) to create a no-op scaler on CPU).\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # detect whether AMP is enabled from the scaler (scaler may be None)\n",
    "    use_amp = (scaler is not None) and getattr(scaler, \"is_enabled\", None) is not None and scaler.is_enabled()\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "\n",
    "        if not use_amp:\n",
    "            # Standard FP32 training\n",
    "            logits = model(x)\n",
    "            loss = combo_loss(logits, y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        else:\n",
    "            # Mixed precision training (CUDA)\n",
    "            # use torch.amp.autocast (new API)\n",
    "            with torch.amp.autocast(enabled=True, device_type=\"cuda\"):\n",
    "                logits = model(x)\n",
    "                loss = combo_loss(logits, y)\n",
    "\n",
    "            # scale + backward + step + update\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(opt)\n",
    "            scaler.update()\n",
    "\n",
    "        running_loss += loss.item() * x.size(0)\n",
    "\n",
    "    return running_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device=\"cuda\", thresh=0.5, use_amp=False):\n",
    "    \"\"\"\n",
    "    Evaluate model on validation/test loader.\n",
    "    Computes mean IoU and Dice scores.\n",
    "    If use_amp is True and device is CUDA, forward passes run inside autocast for speed/memory.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    dices, ious = [], []\n",
    "\n",
    "    # decide autocast device_type when use_amp True\n",
    "    if use_amp:\n",
    "        ac_kwargs = dict(enabled=True, device_type=\"cuda\")\n",
    "    else:\n",
    "        ac_kwargs = dict(enabled=False, device_type=\"cpu\")\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        if use_amp:\n",
    "            with torch.amp.autocast(**ac_kwargs):\n",
    "                logits = model(x)\n",
    "        else:\n",
    "            logits = model(x)\n",
    "\n",
    "        probs = torch.sigmoid(logits)\n",
    "        pred = (probs > thresh).float()\n",
    "\n",
    "        dices.append(dice_coef(pred, y))\n",
    "        ious.append(iou_score(pred, y))\n",
    "\n",
    "    return float(np.mean(ious)), float(np.mean(dices))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d32de240",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T10:01:52.759618Z",
     "iopub.status.busy": "2025-08-24T10:01:52.759427Z",
     "iopub.status.idle": "2025-08-24T11:01:15.948212Z",
     "shell.execute_reply": "2025-08-24T11:01:15.947380Z"
    },
    "papermill": {
     "duration": 3563.194131,
     "end_time": "2025-08-24T11:01:15.949434",
     "exception": false,
     "start_time": "2025-08-24T10:01:52.755303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Training UNet -----\n",
      "Epoch 01 | Loss 0.5097 | IoU 0.3853 | Dice 0.4144\n",
      "Epoch 02 | Loss 0.4781 | IoU 0.5360 | Dice 0.5611\n",
      "Epoch 03 | Loss 0.4748 | IoU 0.1631 | Dice 0.1996\n",
      "Epoch 04 | Loss 0.4708 | IoU 0.2686 | Dice 0.3055\n",
      "Epoch 05 | Loss 0.4610 | IoU 0.2971 | Dice 0.3358\n",
      "\n",
      "----- Training AttentionUNet -----\n",
      "Epoch 01 | Loss 0.5082 | IoU 0.6591 | Dice 0.6591\n",
      "Epoch 02 | Loss 0.4806 | IoU 0.4826 | Dice 0.5123\n",
      "Epoch 03 | Loss 0.4760 | IoU 0.6248 | Dice 0.6460\n",
      "Epoch 04 | Loss 0.4707 | IoU 0.5176 | Dice 0.5471\n",
      "Epoch 05 | Loss 0.4681 | IoU 0.2950 | Dice 0.3291\n",
      "⏹️ Early stopping at epoch 5 (no improvement for 4 epochs)\n",
      "\n",
      "----- Training ResUNet -----\n",
      "Epoch 01 | Loss 0.4865 | IoU 0.2448 | Dice 0.2832\n",
      "Epoch 02 | Loss 0.4523 | IoU 0.5122 | Dice 0.5519\n",
      "Epoch 03 | Loss 0.4289 | IoU 0.5487 | Dice 0.5872\n",
      "Epoch 04 | Loss 0.4199 | IoU 0.5372 | Dice 0.5790\n",
      "Epoch 05 | Loss 0.4121 | IoU 0.5768 | Dice 0.6192\n",
      "\n",
      "----- Training UNet+ -----\n",
      "Epoch 01 | Loss 0.4969 | IoU 0.6109 | Dice 0.6218\n",
      "Epoch 02 | Loss 0.4751 | IoU 0.4169 | Dice 0.4501\n",
      "Epoch 03 | Loss 0.4602 | IoU 0.4627 | Dice 0.4999\n",
      "Epoch 04 | Loss 0.4491 | IoU 0.4155 | Dice 0.4560\n",
      "Epoch 05 | Loss 0.4419 | IoU 0.6208 | Dice 0.6493\n",
      "\n",
      "----- Training SmallUNet -----\n",
      "Epoch 01 | Loss 0.5350 | IoU 0.3518 | Dice 0.3703\n",
      "Epoch 02 | Loss 0.4818 | IoU 0.3097 | Dice 0.3354\n",
      "Epoch 03 | Loss 0.4739 | IoU 0.4421 | Dice 0.4608\n",
      "Epoch 04 | Loss 0.4700 | IoU 0.5378 | Dice 0.5650\n",
      "Epoch 05 | Loss 0.4591 | IoU 0.4848 | Dice 0.5150\n",
      "\n",
      "=== Validation Results (higher is better) ===\n",
      "           Model       IoU      Dice\n",
      "0  AttentionUNet  0.659091  0.659091\n",
      "1          UNet+  0.620830  0.649310\n",
      "2        ResUNet  0.576806  0.619179\n",
      "3      SmallUNet  0.537761  0.564970\n",
      "4           UNet  0.536024  0.561070\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# ============================\n",
    "# 5) Run Experiments (with Early Stopping + AMP)\n",
    "# ============================\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "EPOCHS = 5      # max epochs\n",
    "LR = 1e-3\n",
    "PATIENCE = 4     # stop if no improvement for N epochs\n",
    "\n",
    "MODELS = {\n",
    "    \"UNet\": UNet(),\n",
    "    \"AttentionUNet\": AttentionUNet(),\n",
    "    \"ResUNet\" : ResUNet(),\n",
    "    \"UNet+\" : UNetPlusPlus(),\n",
    "    \"SmallUNet\": SimpleUNet(),\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "# Device in your notebook can be a torch.device or a string — handle both robustly\n",
    "# Make sure DEVICE variable is set in your notebook (e.g., torch.device(\"cuda\") or \"cuda\" or \"cpu\")\n",
    "# If not set, fall back to detecting CUDA availability.\n",
    "try:\n",
    "    DEVICE  # noqa: F821\n",
    "except NameError:\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Decide whether to use AMP: require both CUDA available and DEVICE referring to CUDA\n",
    "use_amp = torch.cuda.is_available() and _is_cuda_device(DEVICE)\n",
    "\n",
    "# Create a GradScaler that is enabled only when AMP is desired.\n",
    "# On CPU this becomes a disabled/no-op scaler if enabled=False.\n",
    "# Use enabled flag instead of deprecated torch.cuda.amp.GradScaler(...)\n",
    "scaler_for_training = torch.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "for name, net in MODELS.items():\n",
    "    print(f\"\\n----- Training {name} -----\")\n",
    "    net = net.to(DEVICE)\n",
    "    opt = torch.optim.AdamW(net.parameters(), lr=LR, weight_decay=1e-4)\n",
    "\n",
    "    # For each model we pass the same scaler instance (it's stateful) but you can also create per-model if preferred.\n",
    "    scaler = scaler_for_training if use_amp else None\n",
    "\n",
    "    best_val = -1.0\n",
    "    best_ckpt = None\n",
    "    patience_counter = 0  # for early stopping\n",
    "\n",
    "    for e in range(1, EPOCHS + 1):\n",
    "        # train\n",
    "        tr_loss = train_one_epoch(net, train_loader, opt, scaler, device=DEVICE)\n",
    "\n",
    "        # validate (use_amp flag ensures autocast during forward if CUDA+AMP)\n",
    "        iou, dice = evaluate(net, val_loader, device=DEVICE, use_amp=use_amp)\n",
    "        print(f\"Epoch {e:02d} | Loss {tr_loss:.4f} | IoU {iou:.4f} | Dice {dice:.4f}\")\n",
    "\n",
    "        # check improvement\n",
    "        if dice > best_val:\n",
    "            best_val = dice\n",
    "            patience_counter = 0\n",
    "            best_ckpt = {k: v.cpu().clone() for k, v in net.state_dict().items()}\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= PATIENCE:\n",
    "                print(f\"⏹️ Early stopping at epoch {e} (no improvement for {PATIENCE} epochs)\")\n",
    "                break\n",
    "\n",
    "    # reload best checkpoint and re-evaluate\n",
    "    if best_ckpt is not None:\n",
    "        net.load_state_dict(best_ckpt)\n",
    "        iou, dice = evaluate(net, val_loader, device=DEVICE, use_amp=use_amp)\n",
    "\n",
    "    results.append({\"Model\": name, \"IoU\": iou, \"Dice\": dice})\n",
    "\n",
    "# ============================\n",
    "# Results table & plot\n",
    "# ============================\n",
    "df = pd.DataFrame(results).sort_values(\"Dice\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n=== Validation Results (higher is better) ===\")\n",
    "print(df)\n",
    "\n",
    "# Bar plot\n",
    "ax = df.set_index(\"Model\")[[\"IoU\", \"Dice\"]].plot(kind=\"bar\", figsize=(7,4))\n",
    "ax.set_ylabel(\"Score\")\n",
    "ax.set_title(\"Segmentation Results — IoU & Dice\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8aadaa65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T11:01:15.961553Z",
     "iopub.status.busy": "2025-08-24T11:01:15.960907Z",
     "iopub.status.idle": "2025-08-24T11:01:21.259153Z",
     "shell.execute_reply": "2025-08-24T11:01:21.258234Z"
    },
    "papermill": {
     "duration": 5.30576,
     "end_time": "2025-08-24T11:01:21.260775",
     "exception": false,
     "start_time": "2025-08-24T11:01:15.955015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet: output (1, 1, 256, 256), params 30,782,593\n",
      "AttentionUNet: output (1, 1, 256, 256), params 30,954,849\n",
      "SimpleUNet: output (1, 1, 256, 256), params 7,699,009\n",
      "ResUNet: output (1, 1, 256, 256), params 8,113,601\n",
      "UNetPlusPlus: output (1, 1, 256, 256), params 2,108,193\n",
      "Coverage plot failed: name 'pairs' is not defined\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 8) Sanity check: instantiate models & forward pass (use eval to avoid BN noise)\n",
    "# ---------------------------\n",
    "import torch, numpy as np, cv2, matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Define IMG_SIZE globally (keep consistent with your dataset resizing)\n",
    "IMG_SIZE = 256  \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    device_cpu = torch.device(\"cpu\")\n",
    "    x = torch.randn(1, 1, IMG_SIZE, IMG_SIZE, device=device_cpu)\n",
    "\n",
    "    models = {\n",
    "        \"UNet\": UNet(in_ch=1, out_ch=1),\n",
    "        \"AttentionUNet\": AttentionUNet(in_ch=1, out_ch=1),\n",
    "        \"SimpleUNet\": SimpleUNet(in_ch=1, out_ch=1, base=64),\n",
    "        \"ResUNet\": ResUNet(in_ch=1, out_ch=1, base=32),\n",
    "        \"UNetPlusPlus\": UNetPlusPlus(in_ch=1, out_ch=1, base=32),\n",
    "    }\n",
    "\n",
    "    for name, m in models.items():\n",
    "        try:\n",
    "            m = m.to(device_cpu)\n",
    "            m.eval()  # eval avoids BN running-stat surprises with batch-size=1\n",
    "            with torch.no_grad():\n",
    "                y = m(x)\n",
    "            params = sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
    "            print(f\"{name}: output {tuple(y.shape)}, params {params:,}\")\n",
    "        except Exception as e:\n",
    "            print(f\"{name} failed: {e}\")\n",
    "\n",
    "    # Quick evaluate coverage distribution (visual)\n",
    "    try:\n",
    "        cov = []\n",
    "        # use pairs from earlier (rename consistently)\n",
    "        N = min(len(pairs), 2000)   # not pairs_all, just pairs you already built\n",
    "        for _, m in pairs[:N]:\n",
    "            M = np.array(Image.open(m).convert('L'))\n",
    "            Msmall = cv2.resize(M, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)\n",
    "            cov.append(100.0 * (Msmall > 0).sum() / Msmall.size)\n",
    "        cov = np.array(cov)\n",
    "        print(f\"Coverage (first {N}) mean/std/min/max:\", cov.mean(), cov.std(), cov.min(), cov.max())\n",
    "        plt.hist(cov, bins=50, range=(0,100))\n",
    "        plt.title(\"Mask coverage (%)\")\n",
    "        plt.xlabel(\"Coverage %\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(\"Coverage plot failed:\", e)\n",
    "\n",
    "# ---------------------------\n",
    "# End\n",
    "# ---------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994f9652",
   "metadata": {
    "papermill": {
     "duration": 0.00577,
     "end_time": "2025-08-24T11:01:21.276270",
     "exception": false,
     "start_time": "2025-08-24T11:01:21.270500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58815270",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T11:01:21.287808Z",
     "iopub.status.busy": "2025-08-24T11:01:21.287590Z",
     "iopub.status.idle": "2025-08-24T11:01:29.554805Z",
     "shell.execute_reply": "2025-08-24T11:01:29.553973Z"
    },
    "papermill": {
     "duration": 8.274456,
     "end_time": "2025-08-24T11:01:29.556123",
     "exception": false,
     "start_time": "2025-08-24T11:01:21.281667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall (first 2000) - mean/std/min/max: 0.9890090942382812 1.8992447828839054 0.0 11.480712890625\n",
      "Percentiles: [0.0, 0.0, 0.0, 0.0, 0.0, 1.1623382568359375, 5.44158935546875, 7.8813629150390625, 11.480712890625]\n",
      "Count of empty masks in sample: 1334 / 2000\n"
     ]
    }
   ],
   "source": [
    "# RUN: shows coverage distribution for train and val splits\n",
    "import numpy as np, cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "def coverage_list(pairs, nlimit=None):\n",
    "    cov=[]\n",
    "    for i,(img,mask) in enumerate(pairs):\n",
    "        M = cv2.imread(mask, cv2.IMREAD_GRAYSCALE)\n",
    "        if M is None:\n",
    "            from PIL import Image\n",
    "            M = np.array(Image.open(mask).convert('L'))\n",
    "        Msmall = cv2.resize(M, (256,256), interpolation=cv2.INTER_NEAREST)\n",
    "        cov.append(100.0*(Msmall>0).sum()/Msmall.size)\n",
    "        if nlimit and i+1>=nlimit: break\n",
    "    return np.array(cov)\n",
    "\n",
    "# Build pairs list same as before\n",
    "import glob, os\n",
    "root=\"/kaggle/input/lgg-mri-segmentation/kaggle_3m\"\n",
    "pairs=[]\n",
    "exts=(\"*.tif\",\"*.png\",\"*.jpg\")\n",
    "for p in sorted(os.listdir(root)):\n",
    "    d=os.path.join(root,p)\n",
    "    if not os.path.isdir(d): continue\n",
    "    files=[]\n",
    "    for e in exts: files+=glob.glob(os.path.join(d,e))\n",
    "    files=[f for f in sorted(files) if \"_mask\" not in os.path.basename(f)]\n",
    "    for img in files:\n",
    "        base=os.path.splitext(img)[0]\n",
    "        for m in (base+\"_mask.tif\", base+\"_mask.png\", base+\"_mask.jpg\"):\n",
    "            if os.path.exists(m):\n",
    "                pairs.append((img,m)); break\n",
    "\n",
    "# compute coverage for first 2000 (fast)\n",
    "cov = coverage_list(pairs, nlimit=2000)\n",
    "print(\"Overall (first 2000) - mean/std/min/max:\", cov.mean(), cov.std(), cov.min(), cov.max())\n",
    "print(\"Percentiles:\", np.percentile(cov, [0,1,5,25,50,75,95,99,100]).tolist())\n",
    "\n",
    "# If you used random_split earlier, get indices from the same split and compute\n",
    "# assume you used random_split(full_ds, [n_train, n_val], generator=torch.Generator().manual_seed(42))\n",
    "# If you didn't store indices, just show simple counts:\n",
    "print(\"Count of empty masks in sample:\", (cov==0).sum(), \"/\", len(cov))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1e71f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T10:36:17.380411Z",
     "iopub.status.busy": "2025-08-21T10:36:17.379832Z",
     "iopub.status.idle": "2025-08-21T10:36:17.384577Z",
     "shell.execute_reply": "2025-08-21T10:36:17.383866Z",
     "shell.execute_reply.started": "2025-08-21T10:36:17.380388Z"
    },
    "papermill": {
     "duration": 0.005701,
     "end_time": "2025-08-24T11:01:29.568248",
     "exception": false,
     "start_time": "2025-08-24T11:01:29.562547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ceec51",
   "metadata": {
    "papermill": {
     "duration": 0.005583,
     "end_time": "2025-08-24T11:01:29.579699",
     "exception": false,
     "start_time": "2025-08-24T11:01:29.574116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 181273,
     "sourceId": 407317,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3614.122337,
   "end_time": "2025-08-24T11:01:33.170575",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-24T10:01:19.048238",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
